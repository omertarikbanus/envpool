{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f288e9a",
   "metadata": {},
   "source": [
    "## VecAdapter Class\n",
    "\n",
    "Define the VecAdapter class to convert an EnvPool object to a Stable-Baselines3-compatible VecEnv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2a9e5",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define utility functions for argument parsing, user interaction, and model management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de550651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_load_model(args, env, policy_kwargs, use_vecnormalize=True):\n",
    "    \"\"\"Create a new model or load existing one based on user choice.\"\"\"\n",
    "    model_exists = os.path.exists(f\"{args.model_save_path}.zip\")\n",
    "    vecnorm_exists = os.path.exists(f\"{args.model_save_path}_vecnormalize.pkl\")\n",
    "    \n",
    "    # Determine whether to load existing model\n",
    "    should_continue = False\n",
    "    if model_exists:\n",
    "        if args.force_new:\n",
    "            print(f\"Found existing model but --force-new specified. Starting fresh training.\")\n",
    "            should_continue = False\n",
    "        elif args.continue_training:\n",
    "            print(f\"Found existing model and --continue-training specified. Continuing training.\")\n",
    "            should_continue = True\n",
    "        else:\n",
    "            # Interactive mode - ask user\n",
    "            should_continue = ask_continue_or_restart(args.model_save_path)\n",
    "    \n",
    "    if should_continue and model_exists:\n",
    "        print(f\"Loading existing model from {args.model_save_path}.zip\")\n",
    "        \n",
    "        # Load VecNormalize stats if they exist and we're using VecNormalize\n",
    "        if use_vecnormalize and vecnorm_exists:\n",
    "            print(f\"Loading VecNormalize statistics from {args.model_save_path}_vecnormalize.pkl\")\n",
    "            env = VecNormalize.load(f\"{args.model_save_path}_vecnormalize.pkl\", env)\n",
    "            # Important: set training=True to continue updating statistics\n",
    "            env.training = True\n",
    "        \n",
    "        model = PPO.load(f\"{args.model_save_path}.zip\", env=env)\n",
    "        print(\"Model loaded successfully. Continuing training...\")\n",
    "    else:\n",
    "        print(\"Creating new model...\")\n",
    "        model = PPO(\n",
    "            policy=\"MlpPolicy\",\n",
    "            env=env,\n",
    "\n",
    "            # ───── PPO hyper-parameters (Appendix, Table \"Hyperparameters for Proximal Policy Gradient\") ─────\n",
    "            learning_rate=1e-4,      # \"Adam stepsize\" ≈ 1 × 10⁻³\n",
    "            clip_range=0.2,            # tighten the trust‐region\n",
    "            target_kl=0.01,            # early stop if KL > 1%\n",
    "            n_steps=4096,           # 5 000 samples/iteration (match 5 000 MuJoCo steps)\n",
    "            batch_size=1024,        # \"Minibatch size\"\n",
    "            n_epochs=8,              # \"Number epochs\"\n",
    "            gamma=0.99,              # \"Discount (γ)\"\n",
    "            gae_lambda=0.95,         # standard value; paper does not override\n",
    "            max_grad_norm=0.5,      # \"Max gradient norm\"\n",
    "            ent_coef=0.1,            # paper does not add entropy bonus\n",
    "            vf_coef=1.0,             # SB3 default; paper gives no separate weight\n",
    "\n",
    "            # ───── bookkeeping ─────\n",
    "            tensorboard_log=\"runs/ppo_taskspace\",\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            verbose=1,\n",
    "        )\n",
    "        print(\"New model created.\")\n",
    "    \n",
    "    return model, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3d442db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Environment: Humanoid-v4\n",
      "Number of environments: 128\n",
      "Seed: 0\n",
      "Total timesteps: 100,000,000\n",
      "Use VecNormalize: True\n",
      "Model save path: ./quadruped_ppo_model\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters - modify these as needed\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.env_name = \"Humanoid-v4\"\n",
    "        self.num_envs = 128\n",
    "        self.seed = 0\n",
    "        self.total_timesteps = 100_000_000\n",
    "        self.tb_log_dir = \"./logs\"\n",
    "        self.model_save_path = \"./quadruped_ppo_model\"\n",
    "        self.render_mode = False\n",
    "        self.continue_training = False\n",
    "        self.force_new = False\n",
    "        self.use_vecnormalize = True  # Enable VecNormalize by default\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Display current configuration\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Environment: {args.env_name}\")\n",
    "print(f\"Number of environments: {args.num_envs}\")\n",
    "print(f\"Seed: {args.seed}\")\n",
    "print(f\"Total timesteps: {args.total_timesteps:,}\")\n",
    "print(f\"Use VecNormalize: {args.use_vecnormalize}\")\n",
    "print(f\"Model save path: {args.model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a7fd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to runs_csv/20250807_105817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Experiment: quadruped_ppo_experiment\n",
      "INFO:root:Using EnvPool for environment Humanoid-v4 with 128 envs. Seed: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory: runs_csv/20250807_105817\n"
     ]
    }
   ],
   "source": [
    "# Set up logging and directories\n",
    "run_dir = os.path.join(\"runs_csv\", datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# Build a logger that keeps every format (stdout, log, tensorboard, csv)\n",
    "logger = configure(\n",
    "    run_dir,\n",
    "    format_strings=(\"stdout\", \"log\", \"tensorboard\", \"csv\")\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(\"Experiment: quadruped_ppo_experiment\")\n",
    "logging.info(f\"Using EnvPool for environment {args.env_name} with {args.num_envs} envs. Seed: {args.seed}\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "print(f\"Log directory: {run_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply VecNormalize if requested (BEFORE VecMonitor)\n",
    "vecnormalize_wrapper = None\n",
    "if args.use_vecnormalize:\n",
    "    print(\"Using VecNormalize wrapper...\")\n",
    "    vecnormalize_wrapper = VecNormalize(env, norm_obs=True, norm_reward=True, clip_reward=10.0)\n",
    "    env = vecnormalize_wrapper\n",
    "\n",
    "env = VecMonitor(env)  # Monitor for tracking episode stats\n",
    "\n",
    "print(\"Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policy network architecture\n",
    "policy_kwargs = dict(\n",
    "    # 2 hidden layers, 256 units each, Tanh activation\n",
    "    activation_fn=th.nn.Tanh,\n",
    "    net_arch=[dict(pi=[256,256], vf=[256,256])],  # 2 hidden layers with 256 units each\n",
    "    # initialise exploration noise to exp(–2.0) ≈ 0.135\n",
    "    log_std_init=-2.0,\n",
    ")\n",
    "\n",
    "print(\"Policy architecture:\")\n",
    "print(f\"  Activation function: {policy_kwargs['activation_fn'].__name__}\")\n",
    "print(f\"  Network architecture: {policy_kwargs['net_arch']}\")\n",
    "print(f\"  Log std init: {policy_kwargs['log_std_init']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bb247",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Start the training process. You can interrupt this cell to stop training early."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
